{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/harjeet88/llm-course/blob/main/empty_notebook.ipynb",
      "authorship_tag": "ABX9TyOoSyE+ziqFRlG9Pv2JmVNs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harjeet88/llm-course/blob/main/3_module/1_document_summariser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install the Google Generative AI SDK\n",
        "!pip install -q openai google-generativeai"
      ],
      "metadata": {
        "id": "ZZmOBXNFKRwm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import libraries\n",
        "import os\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "#import google.generativeai as genai\n",
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "A0aQlfNRKa_L"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "WxkB_NqnJfBa"
      },
      "outputs": [],
      "source": [
        "# Step 3\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "GEMINI_API_KEY=GOOGLE_API_KEY\n",
        "gemini_model='gemini-2.5-flash'\n",
        "gemini_api_endpoint=\"https://generativelanguage.googleapis.com/v1beta/openai/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Initialize the model (using Gemini flash)\n",
        "# Configure OpenAI client to use Google's Gemini endpoint\n",
        "gemini = OpenAI(api_key=GOOGLE_API_KEY, base_url=gemini_api_endpoint)"
      ],
      "metadata": {
        "id": "pIB4Syqu24ZV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system=\"you are a helpful assistant\""
      ],
      "metadata": {
        "id": "HDkkEThMAtSP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"Explain quantum entanglement in simple terms\""
      ],
      "metadata": {
        "id": "jTp_GFT45VXJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a chat completion request (Gemini flash)\n",
        "response = gemini.chat.completions.create(\n",
        "    model=gemini_model,  # Specify Gemini model\n",
        "    messages=[\n",
        "        {   \"role\": \"system\", \"content\": system,\n",
        "            \"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    stream=False,  # Set to True for streaming\n",
        "    temperature=0.7,\n",
        "    max_tokens=2048\n",
        ")"
      ],
      "metadata": {
        "id": "WFxWr2DxKg5C"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(text):\n",
        "    response = gemini.chat.completions.create(\n",
        "        model=gemini_model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a news editor. Summarize in 3 bullet points.\"},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ],\n",
        "        stream=False,\n",
        "        temperature=0.7,\n",
        "        max_tokens=2048\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "guwaY3sqBm9k"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_article(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    paragraphs = soup.find_all('p')\n",
        "    return ' '.join(p.text for p in paragraphs[:5])  # First 5 paragraphs"
      ],
      "metadata": {
        "id": "BsY1TUv2By6h"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BBC News Example\n",
        "url = \"https://www.bbc.com/news/articles/c4g8r34nxeno\"\n",
        "article = get_article(url)\n",
        "print(article)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXmZa_XJB91A",
        "outputId": "4859943c-c9cc-41d4-b673-26464a1b5f35"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elon Musk's artificial intelligence start-up xAI says it is working to remove \"inappropriate\" posts made by its chatbot, Grok, after users shared how it made positive references to Hitler. Screenshots published on social media show the chatbot saying the Nazi leader would be the best person to respond to alleged \"anti-white hate.\" \"Since being made aware of the content, xAI has taken action to ban hate speech before Grok posts on X,\" the company said in a post. ADL, an organisation formed to combat antisemitism and other forms of discrimination, said the posts were \"irresponsible, dangerous and antisemitic.\" \"This supercharging of extremist rhetoric will only amplify and encourage the antisemitism that is already surging on X and many other platforms,\" ADL wrote on X.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=summarize(article)"
      ],
      "metadata": {
        "id": "A8BUMCo6CDYS"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "vodiKLXWLAHH",
        "outputId": "013969d9-621a-48b1-f27c-e3607ddd56d5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's a 3-bullet point summary:\n\n*   Elon Musk's xAI is addressing \"inappropriate\" posts by its Grok chatbot, after users shared instances where it made positive references to Hitler in response to alleged \"anti-white hate.\"\n*   xAI announced it has taken action to \"ban hate speech\" before Grok posts on X, stating it is working to remove such content.\n*   The ADL condemned the posts as \"irresponsible, dangerous and antisemitic,\" warning they could amplify extremist rhetoric and antisemitism on X and other platforms."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BXuvSiy01kzo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}